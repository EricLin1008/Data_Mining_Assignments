{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Mining: Basic Concepts - Winter 2023/24\n",
    "---------------\n",
    "``` \n",
    "> University of Konstanz \n",
    "> Department of Computer and Information Science\n",
    "> Maximilian T. Fischer, Frederik Dennig, Yannick Metz, Udo Schlegel\n",
    "```\n",
    "__Organize in teams of 2 people, return the exercise on time using ILIAS__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 08 in Python \n",
    "---------------\n",
    "- ___Please put your names and student IDs here___:\n",
    "    - Wei-Cheng Lin, 01/1348028\n",
    "    - Kuon Ito, 01/1358810"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 1: Lazy vs Eager: Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Explain the difference between an eager learner and a lazy learner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "An eager learner builds a model during the training phase and generalizes from that model to make predictions on new, unseen data. Meanwhile, a lazy learner defers the process of generalizing the training data until it receives a new, unseen instance that needs a prediction. Lazy learners do not build a model during the training phase. Instead, they store the entire training dataset and generalize from it when a prediction is needed. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Provide an example of a machine learning algorithm that is an eager learner and one that is a lazy learner.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Eager Learner: Random Forest\n",
    "Lazy Learner: k-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given a dataset with 1 million rows and 10 columns. You need to build a machine learning model to predict a binary outcome based on the values in the columns. You have two options: a decision tree or a k-nearest neighbors algorithm.   \n",
    "  \n",
    "**c) Which algorithm should you choose and why? Explain your reasoning in detail, taking into account the size and complexity of the dataset and the computational resources available to you.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "In this dataset, using a Decision Tree may provide better outcome.\n",
    "\n",
    "(1)Efficiency: Decision trees are efficient to train and can handle relatively large datasets.\n",
    "\n",
    "(2)Scalability: Decision trees scale well with the number of instances, and their prediction time is typically faster than KNN.\n",
    "\n",
    "(3)Interpretability: Decision trees provide a straightforward and interpretable model, which can be crucial for understanding and explaining the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 2: Lazy vs Eager: Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we want to implement a basic k-nearest neighbor algorithm.   \n",
    "For this, we need a similarity function and a general k-nearest neighbor function.  \n",
    "We will use the breast cancer dataset we previously used for the SVM with an 80/20 train test split.    \n",
    "  \n",
    "**Please implement the k-nearest neighbor algorithm on your own and show that the implementation works for the breast cancer data.**  \n",
    "_(Hint: use the `sklearn.model_selection.train_test_split` method and the parameter `random_state=0`)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bc/wj9fb4sn72x23376jk6n_b5w0000gn/T/ipykernel_4004/2543260358.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mknn_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {accuracy * 100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             ):\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_2d_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                     return np.stack(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;31m# the weighting so we do not compute them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    848\u001b[0m         )\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m             results = ArgKmin.compute(\n\u001b[0m\u001b[1;32m    851\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \"\"\"\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             return ArgKmin64.compute(\n\u001b[0m\u001b[1;32m    268\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36mthreadpool_limits\u001b[0;34m(limits, user_api)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreadpool_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, limits, user_api)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_threadpool_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_set_threadpool_limits\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         modules = _ThreadpoolInfo(prefixes=self._prefixes,\n\u001b[0m\u001b[1;32m    269\u001b[0m                                   user_api=self._user_api)\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_if_incompatible_openmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_load_modules\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;34m\"\"\"Loop through loaded libraries and store supported ones\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"darwin\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_modules_with_dyld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"win32\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_modules_with_enum_process_module_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_find_modules_with_dyld\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Store the module if it is supported and selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_module_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_find_modules_with_enum_process_module_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m_make_module_from_path\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefixes\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0muser_api\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0mmodule_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minternal_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_RTLD_NOLOAD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_extra_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py\u001b[0m in \u001b[0;36mget_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    644\u001b[0m                              lambda: None)\n\u001b[1;32m    645\u001b[0m         \u001b[0mget_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"OpenBLAS\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=9)\n",
    "\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 3: Evaluation Metrics Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Explain why different evaluation metrics are used for evaluating the performance of classifiers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " Classifiers may be designed with different objectives in mind, such as accuracy, precision, recall, F1 score, or area under the ROC curve (AUC-ROC). These metrics capture different dimensions of performance, and the choice depends on the specific goals of the application. For example, in medical diagnoses, false positives and false negatives may have different consequences, leading to the preference for precision/recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Provide examples of common evaluation metrics for classification algorithms, and explain the strengths and limitations of each metric in the context of classifier evaluation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Accuracy:\n",
    "    Strengths: Simple and intuitive metric representing the ratio of correctly classified instances.\n",
    "    Limitations: Misleading in imbalanced datasets, especially when classes have different prevalences.\n",
    "\n",
    "Precision:\n",
    "    Strengths: Useful when the cost of false positives is high.\n",
    "    Limitations: Alone may not provide balance between false positives and false negatives, affected by imbalanced datasets.\n",
    "\n",
    "Recall (Sensitivity or True Positive Rate):\n",
    "    Strengths: Valuable when the cost of false negatives is high.\n",
    "    Limitations: May not offer a complete picture, especially in the trade-off between false positives and false negatives.\n",
    "\n",
    "Receiver Operating Characteristic (ROC) Curve:\n",
    "    Strengths: Visual representation of performance, threshold independence, and facilitates easy model comparison.\n",
    "    Limitations: Less informative for imbalanced datasets, doesn't indicate optimal threshold, assumes equal misclassification costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Explain how a perfect precision-recall curve looks like.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Visually, on a precision-recall curve, this perfection is represented by a line that starts from the origin (0,0) and goes to the point (1,1), forming a right-angled triangle with the x-axis and y-axis. The area under this perfect curve is 1, indicating ideal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise 4: Evaluation Metrics Practical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After thinking about the different evaluation metrics, we want to see them in real-world scenarios and inspect their workings.  \n",
    "We tackle two datasets for this task and use the machine learning algorithms we have already explored.  \n",
    "The first dataset will be the breast cancer dataset again. The second one will be the cover-type forest dataset.  \n",
    "Both datasets have unique properties and need special care. Handling different data is not always easy and selecting proper algorithms is even more challenging.\n",
    "Thus, we focus on the different evaluation metrics to select one good working algorithm.  \n",
    "In this case, we will compare the sci-kit learn implementations of Naive Bayes, Decision Trees, SVMs, and k-Nearest Neighbors based on the classification accuracy and F1-score.  \n",
    "  \n",
    "As the cover type data has more than two classes, we will only use the second and third class samples.  \n",
    "  \n",
    "**Please implement a comparison between the sci-kit learn implementations of Naive Bayes, Decision Trees, SVMs, and k-Nearest Neighbors on the breast cancer data and cover type data for your own implementation of accuracy and F1-score.**    \n",
    "_(Hint: use the `sklearn.model_selection.train_test_split` method and the parameter `random_state=0`)_  \n",
    "_(Hint: use the `sklearn.naive_bayes.GaussianNB`, `sklearn.tree.DecisionTreeClassifier`, `sklearn.svm.SVC`, `sklearn.neighbors.KNeighborsClassifier` methods with default parameters)_  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "cancer_X = cancer_data.data\n",
    "cancer_y = cancer_data.target\n",
    "\n",
    "cancer_X_train, cancer_X_test, cancer_y_train, cancer_y_test = train_test_split(cancer_X, cancer_y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Breast Cancer:\")\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(cancer_X_train, cancer_y_train)\n",
    "y_pred = gnb.predict(cancer_X_test)\n",
    "accuracy = accuracy_score(cancer_y_test, y_pred)\n",
    "f1 = f1_score(cancer_y_test, y_pred, average='binary')  \n",
    "print(f\"Naive Bayes - Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(cancer_X_train, cancer_y_train)\n",
    "y_pred = clf.predict(cancer_X_test)\n",
    "accuracy = accuracy_score(cancer_y_test, y_pred)\n",
    "f1 = f1_score(cancer_y_test, y_pred, average='binary')  \n",
    "print(f\"Decision Tree - Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(cancer_X_train, cancer_y_train)\n",
    "y_pred = clf.predict(cancer_X_test)\n",
    "accuracy = accuracy_score(cancer_y_test, y_pred)\n",
    "f1 = f1_score(cancer_y_test, y_pred, average='binary')  \n",
    "print(f\"SVM - Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "knn_classifier.fit(cancer_X_train, cancer_y_train)\n",
    "y_pred = knn_classifier.predict(cancer_X_test)\n",
    "accuracy = accuracy_score(cancer_y_test, y_pred)\n",
    "f1 = f1_score(cancer_y_test, y_pred, average='binary')  \n",
    "print(f\"k-Nearest Neighbors - Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_covtype\n",
    "data = fetch_covtype()\n",
    "\n",
    "target = data['target'][np.logical_or(data['target'] == 2, data['target'] == 3)] - 2\n",
    "data = data['data'][np.logical_or(data['target'] == 2, data['target'] == 3)]\n",
    "\n",
    "cover_X_train, cover_X_test, cover_y_train, cover_y_test = train_test_split(data, target, test_size=0.2, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cover_X_train_scaled = scaler.fit_transform(cover_X_train)\n",
    "cover_X_test_scaled = scaler.transform(cover_X_test)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "cover_X_train = pca.fit_transform(cover_X_train_scaled)\n",
    "cover_X_test = pca.transform(cover_X_test_scaled)\n",
    "\n",
    "print(\"Cover-Type Forest(Classes 2 and 3):\")\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(cover_X_train, cover_y_train)\n",
    "y_pred = gnb.predict(cover_X_test)\n",
    "accuracy = accuracy_score(cover_y_test, y_pred)\n",
    "f1 = f1_score(cover_y_test, y_pred, average='binary')  \n",
    "print(f\"Naive Bayes - Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(cover_X_train, cover_y_train)\n",
    "y_pred = clf.predict(cover_X_test)\n",
    "accuracy = accuracy_score(cover_y_test, y_pred)\n",
    "f1 = f1_score(cover_y_test, y_pred, average='binary')  \n",
    "print(f\"Decision Tree - Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(cover_X_train, cover_y_train)\n",
    "y_pred = clf.predict(cover_X_test)\n",
    "accuracy = accuracy_score(cover_y_test, y_pred)\n",
    "f1 = f1_score(cover_y_test, y_pred, average='binary')  \n",
    "print(f\"SVM - Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "knn_classifier.fit(cover_X_train, cover_y_train)\n",
    "y_pred = knn_classifier.predict(cover_X_test)\n",
    "accuracy = accuracy_score(cover_y_test, y_pred)\n",
    "f1 = f1_score(cover_y_test, y_pred, average='binary')  \n",
    "print(f\"k-Nearest Neighbors - Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<span style=\"color:orange\">Feedback: </span>***\n",
    " - 3c) Wrong. Do not use ChatGPT for that.\n",
    " - 4a) No own implementation of accuracy and F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***<span style=\"color:orange\">Okay. Grade: Yellow</span>***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "116075abdc1ed53ddb80f9e3462a1a87c17f9d858d16aae38864710ebb8faa39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
